{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "AgentSourceCode.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Research Assistant Agent: LARA\n"
      ],
      "metadata": {
        "id": "6qVDBDYd4hi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "!pip install langchain langchain-community langchain-core openai langchain-openai tavily-python google-search-results\n",
        "# Mounts google drive for memory storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j-5OLzsihGSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "# Langchain Tools/Models\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.prompts import PromptTemplate\n",
        "# Web/Academic Search\n",
        "from tavily import TavilyClient\n",
        "from serpapi import GoogleSearch\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "u5zfKpuRhGYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API Keys\n",
        "os.environ['TavilyAPIKey'] = userdata.get('TavilyAPIKey')\n",
        "os.environ['OpenAIAPIKey'] = userdata.get('OpenAIAPIKey')\n",
        "os.environ['SerpAPIKey'] = userdata.get('SerpAPIKey')\n",
        "tavilykey = os.environ.get('TavilyAPIKey')\n",
        "serpkey = os.environ.get('SerpAPIKey')\n",
        "openaikey = os.environ.get('OpenAIAPIKey')"
      ],
      "metadata": {
        "id": "UG7PdcxshGL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keyword Definition\n",
        "def generate_keywords(topic):\n",
        "    prompt = f\"Extract key research keywords from this topic: {topic}\" # Prompts the model to find keywords from the input\n",
        "    response = ChatOpenAI(model=\"gpt-4\", api_key=openaikey).invoke(prompt) # Initializes GPT-4 to complete the prompt\n",
        "    return response.content.split(\", \")"
      ],
      "metadata": {
        "id": "zlNEzj82gyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Security Check for Inappropriate/Harmful Content\n",
        "def check_inappropriate_content(topic):\n",
        "    sexual_keywords = [\n",
        "        'sex', 'porn', 'erotic', 'adult', 'nsfw',\n",
        "        'nudity', 'explicit', 'prostitution', 'fetish'\n",
        "    ]\n",
        "    dangerous_keywords = [\n",
        "        'violence', 'murder', 'assault', 'terrorism', 'bomb', 'weapon',\n",
        "        'kill', 'explosive', 'firearm', 'harm', 'self-harm'\n",
        "    ]\n",
        "    harmful_keywords = [\n",
        "        'hate speech', 'racism', 'discrimination', 'xenophobia', 'slur',\n",
        "        'abuse', 'harassment', 'bullying', 'defamation'\n",
        "    ]\n",
        "    all_keywords = sexual_keywords + dangerous_keywords + harmful_keywords\n",
        "    topic_lower = topic.lower() # Corrects format for keywords\n",
        "    for keyword in all_keywords:\n",
        "        if re.search(rf'\\b{keyword}\\b', topic_lower):\n",
        "            return True, f\"Inapropriate Request'{keyword}'. Provide a safer topic to research.\" # Cancels Input Request\n",
        "# Identifies innapropriate patterns through words, making exceptions if they don't match.\n",
        "    inappropriate_patterns = [\n",
        "        r'sex.*(guide|tutorial|instruction)',\n",
        "        r'(make|build|create).*(bomb|weapon|explosive)',\n",
        "        r'(promot|encourag|incit).*hatred',\n",
        "        r'(how to|guide to).*(kill|harm|murder)'\n",
        "    ]\n",
        "    for pattern in inappropriate_patterns:\n",
        "        if re.search(pattern, topic_lower):\n",
        "            return True, \"The topic has been flagged as inappropriate, dangerous, or harmful.\" # Cancels Input Request\n",
        "    return False, \"\""
      ],
      "metadata": {
        "id": "fxYl8CUigy0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory System\n",
        "# Saves input, report, and feedback to a google drive.\n",
        "def save_interaction(topic, report, feedback=None):\n",
        "    data = {\"topic\": topic, \"report\": report, \"feedback\": feedback}\n",
        "    filename = f\"/content/drive/MyDrive/research_{topic.replace(' ', '_')}.json\"\n",
        "    try:\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(data, f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error Saving Memory: {e}\")\n",
        "# Checks and loads previously saved feedback from google drive.\n",
        "def load_previous_feedback():\n",
        "    feedback_list = []\n",
        "    try:\n",
        "        for filename in os.listdir(\"/content/drive/MyDrive/\"):\n",
        "            if filename.startswith(\"research_\") and filename.endswith(\".json\"):\n",
        "                with open(f\"/content/drive/MyDrive/{filename}\", \"r\") as f:\n",
        "                    data = json.load(f)\n",
        "                    if data.get(\"feedback\"):\n",
        "                        feedback_list.append(data[\"feedback\"])\n",
        "        return feedback_list\n",
        "    except Exception as e: # Prints Error Message if Memory System doesn't work.\n",
        "        print(f\"Error Loading Memory: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "T__48bzZgyik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WebSearch and AcademicSearch Functions\n",
        "tavily = TavilyClient(api_key=tavilykey)\n",
        "def websearch(query):\n",
        "    try:\n",
        "        search_response = tavily.search(query=query)\n",
        "        return search_response['results'][:5]  # Limit to top 5 results\n",
        "    except Exception as e: # Allows model to continue if an error occurs.\n",
        "        print(f\"Web search error: {e}\")\n",
        "        return []\n",
        "\n",
        "# SerpAPI for Academic Sources\n",
        "def scholarsearch(query):\n",
        "    try:\n",
        "        params = {\n",
        "            \"engine\": \"google_scholar\",\n",
        "            \"q\": query,\n",
        "            \"api_key\": userdata.get('SerpAPIKey'),\n",
        "            \"num\": 2  # Limit to 2 results for simplicity\n",
        "        }\n",
        "        search = GoogleSearch(params)\n",
        "        results = search.get_dict().get('organic_results', [])[:2]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Academic search error: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "rBlvlmFIgyn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Citation Format/Generation\n",
        "def generate_citation(source):\n",
        "    try:\n",
        "        if isinstance(source, dict):\n",
        "            if 'title' in source and 'url' in source:\n",
        "                title = source['title']\n",
        "                url = source['url']\n",
        "                date = source.get('published_date', 'n.d.')\n",
        "                return f\"{title}. ({date}). Retrieved from {url}\"\n",
        "            else:\n",
        "                return \"Citation unavailable: missing title or url\" # Has multiple checks for different types of data (list,dict,str) and errors for missing data.\n",
        "        elif hasattr(source, 'title') and hasattr(source, 'url'):\n",
        "            title = source.title\n",
        "            url = source.url\n",
        "            year = getattr(source, 'year', 'n.d.')\n",
        "            if hasattr(source, 'authors'):\n",
        "                authors = source.authors\n",
        "                if isinstance(authors, list):\n",
        "                    author_names = []\n",
        "                    for author in authors:\n",
        "                        if isinstance(author, dict):\n",
        "                            author_names.append(author.get('name', 'Unknown'))\n",
        "                        elif hasattr(author, 'name'):\n",
        "                            author_names.append(author.name)\n",
        "                        else:\n",
        "                            author_names.append(str(author))\n",
        "                    authors_str = ', '.join(author_names)\n",
        "                elif isinstance(authors, str):\n",
        "                    authors_str = authors\n",
        "                else:\n",
        "                    authors_str = 'Unknown Author'\n",
        "            else:\n",
        "                authors_str = 'Unknown Author'\n",
        "            return f\"{authors_str}. ({year}). {title}. Retrieved from {url}\"\n",
        "        else:\n",
        "            return \"Citation unavailable: missing title or url\"\n",
        "    except Exception as e:\n",
        "        print(f\"Citation generation error: {e}, source type: {type(source)}\")\n",
        "        return \"Citation unavailable\""
      ],
      "metadata": {
        "id": "ViogpgDigylO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent Tools\n",
        "# Web Search using TavilyAPI\n",
        "web_search_tool = Tool(\n",
        "    name=\"WebSearch\",\n",
        "    func=lambda query: websearch(query),\n",
        "    description=\"Search the web for sources. Input: search query. Output: list of sources.\"\n",
        ")\n",
        "# Google Scholar Search using SerpAPI\n",
        "academic_search_tool = Tool(\n",
        "    name=\"AcademicSearch\",\n",
        "    func=lambda query: scholarsearch(query),\n",
        "    description=\"Search academic papers. Input: search query. Output: list of papers.\"\n",
        ")\n",
        "\n",
        "citation_tool = Tool(\n",
        "    name=\"CitationGenerator\",\n",
        "    func=generate_citation,\n",
        "    description=\"Generate a citation from source metadata. Input: source dictionary or object. Output: citation string.\"\n",
        ")\n",
        "\n",
        "tools = [web_search_tool, academic_search_tool, citation_tool]"
      ],
      "metadata": {
        "id": "j9k0412BgygE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt Template for Reasoning/Summarization.\n",
        "prompt_template = \"\"\"\n",
        "You are a research assistant AI. Your task is to research the topic \"{topic}\" and provide a detailed report. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Follow these steps carefully, in order, and explain your reasoning at each stage:\n",
        "\n",
        "1. Understand the Topic\n",
        "   - Think about what the user is asking for. Break down the topic into key concepts.\n",
        "\n",
        "2. Search for Sources\n",
        "   - Use 'WebSearch' to find ONLY 5 varied web sources. Input: a search query based on the topic.\n",
        "   - Use 'AcademicSearch' to find ONLY 2 academic papers. Input: a search query based on the topic.\n",
        "   - Aim for a variety of sources.\n",
        "   - No Duplicates\n",
        "\n",
        "3. Evaluate Sources\n",
        "   - For each source, assess relevance (keywords in title/snippet/abstract).\n",
        "   - Assess credibility (domain, date, author).\n",
        "   - Try to keep only relevant and credible sources. Explain decisions.\n",
        "   - Aim for 3 Web sources, and 2 Academic sources.\n",
        "   - Rank sources based on relevance and credibility.\n",
        "\n",
        "4. Extract Information\n",
        "   - Extract key points from snippets/abstracts.\n",
        "\n",
        "5. Organize Information\n",
        "   - Group into sub-topics based on themes.\n",
        "   - Rank sources within each sub-topic, with reasoning.\n",
        "\n",
        "6. Summarize\n",
        "   - Generate summaries for each sub-topic.\n",
        "   - Identify relations/trends across sources.\n",
        "\n",
        "7. Generate Citations\n",
        "   - Use 'CitationGenerator' for each source.\n",
        "\n",
        "8. Compile the Report\n",
        "   - Rank sources from most relevant/credible to least.\n",
        "   - Structure with sub-topics, summaries, and citations for each source.\n",
        "   - Add overall summary and references.\n",
        "\n",
        "Previous feedback: {feedback}\n",
        "- Avoid results that are not unreliable.\n",
        "- Prioritize preferred sources if mentioned.\n",
        "- Update results based on feedback.\n",
        "\n",
        "When you have compiled the report, present it as:\n",
        "Final Answer:\n",
        "- 5 Sources, Ranked based on relevancy/credbility.\n",
        "- A short summary for each source.\n",
        "- Citations for each source.\n",
        "- Overall summary and references including key connections between the sources.\n",
        "\n",
        "{agent_scratchpad}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XMuJXlr7gydK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Agent\n",
        "llm = ChatOpenAI(model=\"gpt-4\", api_key=openaikey) # Large Language Model powered by GPT-4\n",
        "prompt = PromptTemplate.from_template(prompt_template) # Defines the template prompt above\n",
        "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt) # Creates the agent\n",
        "executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True) # Executes the Agents code."
      ],
      "metadata": {
        "id": "kbM-w7HFgyag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Agent and Request Feedback\n",
        "topic = input(\"Enter a research topic: \")\n",
        "is_inappropriate, rejection_message = check_inappropriate_content(topic) # Prevents code from running if inappropriate\n",
        "if is_inappropriate:\n",
        "    print(rejection_message)\n",
        "else:\n",
        "    feedback = \" \".join(load_previous_feedback()) if load_previous_feedback() else \"No previous feedback available.\" # Loads from memory if available\n",
        "    result = executor.invoke({\n",
        "        \"topic\": topic,\n",
        "        \"feedback\": feedback,\n",
        "        \"tools\": \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools]),\n",
        "        \"tool_names\": \", \".join([tool.name for tool in tools]),\n",
        "        \"agent_scratchpad\": \"\"\n",
        "    })\n",
        "    print(result['output'])\n",
        "\n",
        "    # Update Memory/Request Feedback\n",
        "    user_feedback = input(\"Enter Feedback Here:\")\n",
        "    save_interaction(topic, result['output'], user_feedback)"
      ],
      "metadata": {
        "id": "28Nl5qBggySg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
